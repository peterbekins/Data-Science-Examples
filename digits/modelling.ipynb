{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Recognizer Project\n",
    "## Step 3. Choosing a Model\n",
    "\n",
    "In this notebook I will test the effectiveness of three separate models: linear regression, k-nearest neighbor, and random forest. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load and prepare data\n",
    "\n",
    "The MNIST data was converted into compressed files with CSV format in a previous workbook. To begin, I will load the files into pandas dataframes and sample a smaller dataset to reduce computation time. I will then apply **VarianceThreshold** from scikit-learn to reduce dimensionality of the features followed by **StandardScalar** to help improve the performance of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "train_image_file = './data/mnist_train_images.gz'\n",
    "train_label_file = './data/mnist_train_labels.gz'\n",
    "test_image_file = './data/mnist_test_images.gz'\n",
    "test_label_file = './data/mnist_test_labels.gz'\n",
    "\n",
    "# Read compressed CSV files into pandas dfs \n",
    "x_train = pd.read_csv(train_image_file, index_col = 0, compression = 'gzip')\n",
    "y_train = pd.read_csv(train_label_file, index_col = 0, compression = 'gzip')\n",
    "X_test = pd.read_csv(test_image_file, index_col = 0, compression = 'gzip')\n",
    "Y_test = pd.read_csv(test_label_file, index_col = 0, compression = 'gzip')\n",
    "\n",
    "# Sample a subset of images (10000 train and 1000 test)\n",
    "y_sample = y_train.sample(n=10000)\n",
    "Y_sample = Y_test.sample(n=1000)\n",
    "x_sample = x_train.iloc[y_sample.index.tolist()]\n",
    "X_sample = X_test.iloc[Y_sample.index.tolist()]\n",
    "\n",
    "# Remove low variance features (be sure to only fit on train set to avoid leakage)\n",
    "selector = VarianceThreshold(threshold = 0.25)\n",
    "x_low = selector.fit_transform(x_sample)\n",
    "X_low = selector.transform(X_sample)\n",
    "\n",
    "# Normalize features (be sure to only fit on train set to avoid leakage)\n",
    "scaler = StandardScaler()\n",
    "x = scaler.fit_transform(x_low)\n",
    "X = scaler.transform(X_low)\n",
    "\n",
    "# Convert target variables to 1d array\n",
    "y = y_sample['label'].values\n",
    "Y = Y_sample['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 659)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 659)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Fit and evaluate logistic regression model\n",
    "\n",
    "Multinomial logistic regression can be used to build a model where there are more than two outcomes that are not ordered. The algorithm works by estimating probabilities for a given outcome based on the dependent variables using a logistic function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred [1 3 7 7 6 0 1 5 7 0 7 0 0 3 8 9 8 8 7 1 4 7 0 6 7 2 5 3 1 9]\n",
      "True [1 3 7 7 6 0 1 5 7 0 7 0 2 5 8 9 8 5 7 2 4 7 8 5 7 6 5 3 1 9]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "lm = LogisticRegression(C=20, solver='lbfgs', multi_class='multinomial')\n",
    "lm.fit(x,y)\n",
    "Y_lm = lm.predict(X)\n",
    "print \"Pred\", Y_lm[:30]\n",
    "print \"True\", Y[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.873\n"
     ]
    }
   ],
   "source": [
    "print accuracy_score(Y, Y_lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the logistic model is decent with about 87% of the images in the test set classified correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Fit and evaluate k-nearest neighbors model\n",
    "\n",
    "The k-nearest neighbors classifier computes the distance between feature vectors for each observation and then classifies the observations by grouping them with their nearest neighbors. The parameter k determines how many neighbors to consider when assigning a class to an observation. \n",
    "\n",
    "The value of k can be tuned by using a combination of iteration over a range of possible k values and K-fold cross validation. For each k value, the train data is divided into K folds of equal size (typically 10 are used), and the model is then fit K times with each fold acting once as the test set in order to score the accuracy of the model for that value of k. (Don't confuse the parameters k and K)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "k_value = []\n",
    "accuracy = []\n",
    "for k in range(1,11):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, x, y, cv=10, scoring='accuracy')\n",
    "    k_value.append(k)\n",
    "    accuracy.append(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(k_value, accuracy)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9116005051845472, 0.8935950765129279, 0.9108007012081043, 0.9076051909263396, 0.911504616131476, 0.9094938131343057, 0.9103018909881818, 0.9079976837233339, 0.9077989846534953, 0.9075025731101931]\n"
     ]
    }
   ],
   "source": [
    "print accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This analysis suggests that the accuracy score is relatively stable for odd values of k between 1 and 5. After k=5, accuracy begins to decline. The following model will use k=5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred [1 3 7 7 6 0 1 5 7 0 7 0 2 3 8 9 8 5 7 2 4 7 8 5 7 6 5 3 1 9]\n",
      "True [1 3 7 7 6 0 1 5 7 0 7 0 2 5 8 9 8 5 7 2 4 7 8 5 7 6 5 3 1 9]\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(x,y)\n",
    "Y_knn = knn.predict(X)\n",
    "print \"Pred\", Y_knn[:30]\n",
    "print \"True\", Y[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.907\n"
     ]
    }
   ],
   "source": [
    "print accuracy_score(Y, Y_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the k-nn model is slightly better than the logistic regression, with over 90% of the images in the test set classified correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Fit and evaluate random forest model\n",
    "\n",
    "A random forest classifier is an ensemble method that creates multiple decision trees and then classifies based on the average outcome of the individual trees. This model has several parameters to be tuned, so I will use the **GridSearchCV** method from scikit-learn to optimize the best combination of parameters when fitting the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 'log2', 'n_estimators': 500, 'max_depth': 50}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "rfc = RandomForestClassifier(oob_score = True, random_state=0)\n",
    "param_grid = { \n",
    "    'n_estimators': [50, 100, 500],\n",
    "    'max_depth': [10,25, 50],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)\n",
    "CV_rfc.fit(x,y)\n",
    "\n",
    "print CV_rfc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred [1 3 7 7 6 0 1 5 7 0 7 0 6 3 8 9 8 6 7 2 4 7 8 5 7 6 5 3 1 9]\n",
      "True [1 3 7 7 6 0 1 5 7 0 7 0 2 5 8 9 8 5 7 2 4 7 8 5 7 6 5 3 1 9]\n"
     ]
    }
   ],
   "source": [
    "Y_rfc = CV_rfc.predict(X)\n",
    "print \"Pred\", Y_rfc[:30]\n",
    "print \"True\", Y[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.946\n"
     ]
    }
   ],
   "source": [
    "print accuracy_score(Y, Y_rfc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest model is even better than the k-nn, with almost 95% of the images in the test set classified correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
